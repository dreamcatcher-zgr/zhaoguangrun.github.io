
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../yolo/">
      
      
        <link rel="next" href="../%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.23">
    
    
      
        <title>参数量分析 - 赵广润的网页</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.6543a935.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../assets/javascripts/glightbox.min.js"></script></head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href=".." title="赵广润的网页" class="md-header__button md-logo" aria-label="赵广润的网页" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            赵广润的网页
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              参数量分析
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="赵广润的网页" class="md-nav__button md-logo" aria-label="赵广润的网页" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    赵广润的网页
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    主页
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../mkdocs%E9%85%8D%E7%BD%AE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mkdocs配置
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../markdown%E8%AF%AD%E6%B3%95/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    markdown语法
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    深度学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            深度学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    模型介绍
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            模型介绍
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../yolo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    yolo系列模型
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" checked>
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    LLM技术
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            LLM技术
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    参数量分析
  </span>
  

      </a>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    算法
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            算法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    卡尔曼滤波
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<!DOCTYPE html>
<html lang="en">
<body>
<h1 id="_1">参数量分析<a class="headerlink" href="#_1" title="Permanent link">#</a></h1>
<p>为了方便描述，首先定义各符号的含义：</p>
<ul>
<li><span class="arithmatex"><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>：表示embedding层有多少个词；</li>
<li><span class="arithmatex"><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span>：表示batch_size；</li>
<li><span class="arithmatex"><span class="MathJax_Preview">s</span><script type="math/tex">s</script></span>：表示seq_length，为文本长度；</li>
<li><span class="arithmatex"><span class="MathJax_Preview">h</span><script type="math/tex">h</script></span>：表示hidden_dim，为隐藏层的维度；</li>
<li><span class="arithmatex"><span class="MathJax_Preview">a</span><script type="math/tex">a</script></span>：表示多头注意力中有多个头；</li>
<li><span class="arithmatex"><span class="MathJax_Preview">h_a</span><script type="math/tex">h_a</script></span>：表示hidden_dim_per_head，为多头注意力中每个头的隐藏层维度；</li>
<li><span class="arithmatex"><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>：表示总共有 <span class="arithmatex"><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span> 层 transformer；</li>
</ul>
<p>另外，在实际使用时一般都有 <span class="arithmatex"><span class="MathJax_Preview">h_a * a = h</span><script type="math/tex">h_a * a = h</script></span> 成立。</p>
<h2 id="1bert">1、BERT 参数量<a class="headerlink" href="#1bert" title="Permanent link">#</a></h2>
<h3 id="11-bert">1.1 BERT类模型<a class="headerlink" href="#11-bert" title="Permanent link">#</a></h3>
<p><strong>embedding 层</strong>：参数量为 <span class="arithmatex"><span class="MathJax_Preview">vh</span><script type="math/tex">vh</script></span></p>
<p><strong>MHA 层</strong>：这一层带有参数的有三部分，分别为 QKV 的权重矩阵、dense 层、Layer Norm层，分别计算：</p>
<ul>
<li>
<p>QKV 的权重矩阵：每个权重矩阵的输入向量的维度为 <span class="arithmatex"><span class="MathJax_Preview">h</span><script type="math/tex">h</script></span>，有 <span class="arithmatex"><span class="MathJax_Preview">a</span><script type="math/tex">a</script></span> 个 head，每个 head 的隐层维度是 <span class="arithmatex"><span class="MathJax_Preview">h_a</span><script type="math/tex">h_a</script></span>，则参数量为 <span class="arithmatex"><span class="MathJax_Preview">hah_a=h^2</span><script type="math/tex">hah_a=h^2</script></span>，三个权重矩阵的参数量就是再乘以3，即 <span class="arithmatex"><span class="MathJax_Preview">3h^2</span><script type="math/tex">3h^2</script></span></p>
</li>
<li>
<p>dense 层：这个比较简单，直接就是 <span class="arithmatex"><span class="MathJax_Preview">h^2</span><script type="math/tex">h^2</script></span></p>
</li>
<li>
<p>Layer Norm层：这一层里面不是矩阵乘法，而是向量的相应位置的元素相乘，所以 <span class="arithmatex"><span class="MathJax_Preview">\gamma</span><script type="math/tex">\gamma</script></span> 和 <span class="arithmatex"><span class="MathJax_Preview">\beta</span><script type="math/tex">\beta</script></span> 的参数量是 <span class="arithmatex"><span class="MathJax_Preview">2h</span><script type="math/tex">2h</script></span></p>
</li>
</ul>
<p><strong>FFN 层</strong>：这一层包含两个 dense 层，这两个 dense 层先将维度由 <span class="arithmatex"><span class="MathJax_Preview">h</span><script type="math/tex">h</script></span> 升到 <span class="arithmatex"><span class="MathJax_Preview">4h</span><script type="math/tex">4h</script></span>，再由 <span class="arithmatex"><span class="MathJax_Preview">4h</span><script type="math/tex">4h</script></span> 降到 <span class="arithmatex"><span class="MathJax_Preview">h</span><script type="math/tex">h</script></span>，然后接一个 Layer Norm 层，所以参数量为 <span class="arithmatex"><span class="MathJax_Preview">h*4h+4h*h+2h=8h^2+2h</span><script type="math/tex">h*4h+4h*h+2h=8h^2+2h</script></span></p>
<p>将上述几部分加起来得到每层 transformer 的参数量为 <span class="arithmatex"><span class="MathJax_Preview">12h^2+4h</span><script type="math/tex">12h^2+4h</script></span>，一般会把 <span class="arithmatex"><span class="MathJax_Preview">4h</span><script type="math/tex">4h</script></span> 忽略掉，则参数量为 <span class="arithmatex"><span class="MathJax_Preview">12h^2</span><script type="math/tex">12h^2</script></span>。</p>
<p>将 embedding 层和 <span class="arithmatex"><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span> 层 transformer 加起来总的参数量为 <span class="arithmatex"><span class="MathJax_Preview">n \cdot (12h^2+4h) + vh</span><script type="math/tex">n \cdot (12h^2+4h) + vh</script></span></p>
<h3 id="12-bert">1.2 BERT 模型结构<a class="headerlink" href="#12-bert" title="Permanent link">#</a></h3>
<p>BERT 的模型结构为：vocab 总共有 21128 个，隐藏层维度为 768，12 层 transformer，MHA 中是 12 个 head，每个 head 的隐层维度是 64。官方论文中总参数量为 110M。</p>
<p>将这些参数代入到上一小节的公式中得到：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{split}
&amp;12 * (12 * 768 * 768 + 4 * 768) + 21128 * 768 \\
= &amp;12*(7077888+3072)+16226304 \\ 
= &amp;101197824 \\
= &amp;101M
\end{split}</div>
<script type="math/tex; mode=display">\begin{split}
&12 * (12 * 768 * 768 + 4 * 768) + 21128 * 768 \\
= &12*(7077888+3072)+16226304 \\ 
= &101197824 \\
= &101M
\end{split}</script>
</div>
<p>也就是说大概 101M 的参数量，相比于官方所说的 110M，这其中的差距主要包括最后的分类器层，以及上述计算过程中都没有考虑偏置项（bias）。</p>
<p>BERT结构如下所示：</p>
<pre><code>BertModel(
  (embeddings): BertEmbeddings(
    (word_embeddings): Embedding(21128, 768, padding_idx=0)
    (position_embeddings): Embedding(512, 768)
    (token_type_embeddings): Embedding(2, 768)
    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): BertEncoder(
    (layer): ModuleList(
      (0-11): 12 x BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (intermediate_act_fn): GELUActivation()
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (pooler): BertPooler(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (activation): Tanh()
  )
)
</code></pre>
<h2 id="2llama-65b">2、LLAMA-65B 参数量<a class="headerlink" href="#2llama-65b" title="Permanent link">#</a></h2>
<h3 id="21-llama-65b">2.1 LLAMA-65B 参数量<a class="headerlink" href="#21-llama-65b" title="Permanent link">#</a></h3>
<p>LLAMA 中会使用 SWiGLU 结构，增加一个新的符号：</p>
<ul>
<li><span class="arithmatex"><span class="MathJax_Preview">h_{\text{swi}}</span><script type="math/tex">h_{\text{swi}}</script></span>：表示 SWiGLU 中隐藏层的维度；</li>
</ul>
<p><strong>embedding 层</strong>：参数量为 <span class="arithmatex"><span class="MathJax_Preview">vh</span><script type="math/tex">vh</script></span></p>
<p><strong>MHA 层</strong>：这一层带有参数的有三部分，分别为 QKV 的权重矩阵、dense 层、Layer Norm层，分别计算</p>
<ul>
<li>
<p>QKV 的权重矩阵：每个权重矩阵的输入向量的维度为 <span class="arithmatex"><span class="MathJax_Preview">h</span><script type="math/tex">h</script></span>，有 <span class="arithmatex"><span class="MathJax_Preview">a</span><script type="math/tex">a</script></span> 个 head，每个 head 的隐层维度是 <span class="arithmatex"><span class="MathJax_Preview">h_a</span><script type="math/tex">h_a</script></span>，则参数量为 <span class="arithmatex"><span class="MathJax_Preview">hah_a=h^2</span><script type="math/tex">hah_a=h^2</script></span>，三个权重矩阵的参数量就是再乘以3，即 <span class="arithmatex"><span class="MathJax_Preview">3h^2</span><script type="math/tex">3h^2</script></span></p>
</li>
<li>
<p>dense 层：这个比较简单，直接就是 <span class="arithmatex"><span class="MathJax_Preview">h^2</span><script type="math/tex">h^2</script></span></p>
</li>
<li>
<p>Layer Norm层：这一层里面不是矩阵乘法，而是向量的相应位置的元素相乘，所以 <span class="arithmatex"><span class="MathJax_Preview">\gamma</span><script type="math/tex">\gamma</script></span> 和 <span class="arithmatex"><span class="MathJax_Preview">\beta</span><script type="math/tex">\beta</script></span> 的参数量是 <span class="arithmatex"><span class="MathJax_Preview">2h</span><script type="math/tex">2h</script></span></p>
</li>
</ul>
<p><strong>MLP 层</strong>：LLAMA 中的 MLP 层使用的是 <a href="/1fb1JNJ6/">SWiGLU 结构</a>，从 2.2 小节中可以看到有三个 Linear 结构，总的参数量为：<span class="arithmatex"><span class="MathJax_Preview">3*h*h_{\text{swi}}</span><script type="math/tex">3*h*h_{\text{swi}}</script></span></p>
<p>将上述几部分加起来得到每层 transformer 的参数量为 <span class="arithmatex"><span class="MathJax_Preview">4h^2+3hh_{\text{swi}}+4h</span><script type="math/tex">4h^2+3hh_{\text{swi}}+4h</script></span>，一般会把 <span class="arithmatex"><span class="MathJax_Preview">4h</span><script type="math/tex">4h</script></span> 忽略掉，则参数量为 <span class="arithmatex"><span class="MathJax_Preview">4h^2+3hh_{\text{swi}}</span><script type="math/tex">4h^2+3hh_{\text{swi}}</script></span>。</p>
<p>将 embedding 层和 <span class="arithmatex"><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span> 层 transformer 加起来总的参数量为 <span class="arithmatex"><span class="MathJax_Preview">n \cdot (4h^2+3hh_{\text{swi}}+4h) + vh</span><script type="math/tex">n \cdot (4h^2+3hh_{\text{swi}}+4h) + vh</script></span></p>
<h3 id="22-llama-65b">2.2 LLAMA-65B 模型结构<a class="headerlink" href="#22-llama-65b" title="Permanent link">#</a></h3>
<p>vocab 总共有 32000 个，隐藏层维度为 8192，80 层 transformer，MHA 中是 64 个 head，每个 head 的隐层维度是 128。</p>
<p>将这些参数代入到上一小节的公式中得到：</p>
<div class="arithmatex">
<div class="MathJax_Preview">\begin{split}
&amp;80 * (4 * 8192 * 8192 + 3 * 8192 * 22016 + 4 * 8192) + 32000 * 8192 \\
= &amp;80*(268435456+541065216+32768)+262144000 \\ 
= &amp;65024819200 \\
= &amp;65B
\end{split}</div>
<script type="math/tex; mode=display">\begin{split}
&80 * (4 * 8192 * 8192 + 3 * 8192 * 22016 + 4 * 8192) + 32000 * 8192 \\
= &80*(268435456+541065216+32768)+262144000 \\ 
= &65024819200 \\
= &65B
\end{split}</script>
</div>
<p>也就是说大概 65B 的参数量。</p>
<p>结构如下所示：</p>
<pre><code>LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(32000, 8192, padding_idx=0)
    (layers): ModuleList(
      (0-79): 80 x LlamaDecoderLayer(
        (input_layernorm): LlamaRMSNorm()
        (self_attn): LlamaAttention(
          (q_proj): Linear4bit(in_features=8192, out_features=8192, bias=False)
          (k_proj): Linear4bit(in_features=8192, out_features=8192, bias=False)
          (v_proj): Linear4bit(in_features=8192, out_features=8192, bias=False)
          (o_proj): Linear4bit(in_features=8192, out_features=8192, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (post_attention_layernorm): LlamaRMSNorm()
        (mlp): LlamaMLP(
          (gate_proj): Linear4bit(in_features=8192, out_features=22016, bias=False)
          (down_proj): Linear4bit(in_features=22016, out_features=8192, bias=False)
          (up_proj): Linear4bit(in_features=8192, out_features=22016, bias=False)
          (act_fn): SiLUActivation()
        )
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=8192, out_features=32000, bias=False)
)
</code></pre>
<h2 id="reference">Reference<a class="headerlink" href="#reference" title="Permanent link">#</a></h2>
<ul>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/639872915">https://zhuanlan.zhihu.com/p/639872915</a></p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/624740065">https://zhuanlan.zhihu.com/p/624740065</a></p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/424180513">BertLarge 中间激活值分析</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1910.02054.pdf">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a></p>
</li>
</ul>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../assets/javascripts/bundle.ebd0bdb7.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  </body>
</html>